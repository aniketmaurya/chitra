{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from chitra.core import *\n",
    "from chitra.utils import disable_gpu\n",
    "disable_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chitra\n",
    "> <p align=\"center\">\n",
    "<img src=\"../chitra_banner.png\" alt=\"chitra\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.code-inspector.com/project/16652/score/svg)\n",
    "![](https://www.code-inspector.com/project/16652/status/svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is chitra?\n",
    "\n",
    "**chitra** (**चित्र**) is a Deep Learning Computer Vision library for easy data loading, model building and model visualization with GradCAM/GradCAM++ and Framework agnostic Model Serving.\n",
    "\n",
    "Highlights:\n",
    "- Faster data loading without any boilerplate.\n",
    "- Framework Agnostic Model Serving.\n",
    "- Progressive resizing of images.\n",
    "- Rapid experiments with different models using `chitra.trainer` module.\n",
    "- Train models with cyclic learning rate.\n",
    "- Model interpretation using GradCAM/GradCAM++ with no extra code.\n",
    "\n",
    "\n",
    "If you have more use cases please [**raise an issue**](https://github.com/aniketmaurya/chitra/issues/new/choose) with the feature you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "### Using pip (recommended)\n",
    "\n",
    "`pip install -U chitra`\n",
    "\n",
    "### From source\n",
    "\n",
    "```\n",
    "git clone https://github.com/aniketmaurya/chitra.git\n",
    "cd chitra\n",
    "pip install -e .\n",
    "```\n",
    "\n",
    "### From GitHub\n",
    "```\n",
    "pip install git+https://github.com/aniketmaurya/chitra@master\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage\n",
    "\n",
    "### Loading data for image classification\n",
    "\n",
    "Chitra `dataloader` and `datagenerator` modules for loading data. `dataloader` is a minimal dataloader that returns `tf.data.Dataset` object. `datagenerator` provides flexibility to users on how they want to load and manipulate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import chitra\n",
    "from chitra.dataloader import Clf, show_batch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# cat_dog_path = '/data/aniket/catdog/train/'\n",
    "cat_dog_path = '/Users/aniket/Pictures/data/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dl = Clf()\n",
    "data = clf_dl.from_folder(cat_dog_path, target_shape=(224, 224))\n",
    "\n",
    "clf_dl.show_batch(8, figsize=(8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in data.take(1):\n",
    "    image = e[0].numpy().astype('uint8')\n",
    "    label = e[1].numpy()\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image datagenerator\n",
    "Dataset class provides the flexibility to load image dataset by updating components of the class.\n",
    "\n",
    "Components of Dataset class are:\n",
    "- image file generator\n",
    "- resizer\n",
    "- label generator\n",
    "- image loader\n",
    "\n",
    "These components can be updated with custom function by the user according to their dataset structure. For example the Tiny Imagenet dataset is organized as-\n",
    "\n",
    "```\n",
    "train_folder/\n",
    ".....folder1/\n",
    "    .....file.txt\n",
    "    .....folder2/\n",
    "           .....image1.jpg\n",
    "           .....image2.jpg\n",
    "                     .\n",
    "                     .\n",
    "                     .\n",
    "           ......imageN.jpg\n",
    "                    \n",
    "                      \n",
    "```\n",
    "\n",
    "The inbuilt file generator search for images on the `folder1`, now we can just update the `image file generator` and rest of the functionality will remain same.\n",
    "\n",
    "**Dataset also support progressive resizing of images.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# data_path = '/data/aniket/tiny-imagenet/data/tiny-imagenet-200/train'\n",
    "# data_path = '/Users/aniket/Pictures/data/train'\n",
    "data_path = '/Users/aniket/Pictures/data/tiny-imagenet-200/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chitra.datagenerator import Dataset\n",
    "from glob import glob\n",
    "\n",
    "ds = Dataset(data_path)\n",
    "# it will load the folders and NOT images\n",
    "ds.filenames[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(path):\n",
    "    return glob(f'{path}/*/images/*')\n",
    "\n",
    "def get_label(path):\n",
    "    return path.split('/')[-3]\n",
    "    \n",
    "ds.update_component('get_filenames', load_files)\n",
    "ds.filenames[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progressive resizing\n",
    "\n",
    "> It is the technique to sequentially resize all the images while training the CNNs on smaller to bigger image sizes. Progressive Resizing is described briefly in his terrific fastai course, “Practical Deep Learning for Coders”. A great way to use this technique is to train a model with smaller image size say 64x64, then use the weights of this model to train another model on images of size 128x128 and so on. Each larger-scale model incorporates the previous smaller-scale model layers and weights in its architecture.\n",
    "~[KDnuggets](https://www.kdnuggets.com/2019/05/boost-your-image-classification-model.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_sz_list = [(28, 28), (32, 32), (64, 64)]\n",
    "\n",
    "ds = Dataset(data_path, image_size=image_sz_list)\n",
    "ds.update_component('get_filenames', load_files)\n",
    "ds.update_component('get_label', get_label)\n",
    "\n",
    "\n",
    "print()\n",
    "# first call to generator\n",
    "for img, label in ds.generator():\n",
    "    print('first call to generator:', img.shape)\n",
    "    break\n",
    "\n",
    "# seconds call to generator\n",
    "for img, label in ds.generator():\n",
    "    print('seconds call to generator:', img.shape)\n",
    "    break\n",
    "\n",
    "# third call to generator\n",
    "for img, label in ds.generator():\n",
    "    print('third call to generator:', img.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.data support\n",
    "Creating a `tf.data` dataloader was never as easy as this one liner. It converts the Python generator into `tf.data.Dataset` for a faster data loading, prefetching, caching and everything provided by tf.data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_sz_list = [(28, 28), (32, 32), (64, 64)]\n",
    "\n",
    "ds = Dataset(data_path, image_size=image_sz_list)\n",
    "ds.update_component('get_filenames', load_files)\n",
    "ds.update_component('get_label', get_label)\n",
    "\n",
    "dl = ds.get_tf_dataset()\n",
    "\n",
    "for e in dl.take(1):\n",
    "    print(e[0].shape)\n",
    "\n",
    "for e in dl.take(1):\n",
    "    print(e[0].shape)\n",
    "\n",
    "for e in dl.take(1):\n",
    "    print(e[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer\n",
    "The Trainer class inherits from `tf.keras.Model`, it contains everything that is required for training.\n",
    "It exposes trainer.cyclic_fit method which trains the model using Cyclic Learning rate discovered by [Leslie Smith](https://arxiv.org/abs/1506.01186)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chitra.trainer import Trainer, create_cnn\n",
    "from chitra.datagenerator import Dataset\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset(cat_dog_path, image_size=(224,224))\n",
    "model = create_cnn('mobilenetv2', num_classes=2, name='Cat_Dog_Model')\n",
    "trainer = Trainer(ds, model)\n",
    "# trainer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.compile2(batch_size=8,\n",
    "                 optimizer=tf.keras.optimizers.SGD(1e-3, momentum=0.9, nesterov=True),\n",
    "                 lr_range=(1e-6, 1e-3),\n",
    "                 loss='binary_crossentropy', \n",
    "                 metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.cyclic_fit(epochs=5,\n",
    "                   batch_size=8,\n",
    "                   lr_range=(0.00001, 0.0001),                   \n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Visualization\n",
    "It is important to understand what is going inside the model. Techniques like GradCam and Saliency Maps can visualize what the Network is learning. `trainer` module has InterpretModel class which creates GradCam and GradCam++ visualization with almost no additional code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chitra.trainer import InterpretModel\n",
    "trainer = Trainer(ds, create_cnn('mobilenetv2', num_classes=1000, keras_applications=False))\n",
    "model_interpret = InterpretModel(True, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "trainer.NUM_CLASSES=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = ds[1][0].numpy().astype('uint8')\n",
    "image = Image.fromarray(image)\n",
    "model_interpret(image)\n",
    "print(IMAGENET_LABELS[285])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "image = ds[3][0].numpy().astype('uint8')\n",
    "image = Image.fromarray(image)\n",
    "print(IMAGENET_LABELS[208])\n",
    "model_interpret(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization\n",
    "\n",
    "### Image annotation\n",
    "\n",
    "Thanks to [**fizyr**](https://github.com/fizyr/keras-retinanet) keras-retinanet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chitra.visualization import draw_annotations\n",
    "\n",
    "labels = np.array([label])\n",
    "bbox = np.array([[30, 50, 170, 190]])\n",
    "label_to_name = lambda x: 'Cat' if x==0 else 'Dog'\n",
    "\n",
    "draw_annotations(image, ({'bboxes': bbox, 'labels':labels,}), label_to_name=label_to_name)\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/Users/aniket/Pictures/data/train/dog/download.jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chitra.image import Chitra\n",
    "\n",
    "label = 'Cat' if label==0 else 'Dog'\n",
    "\n",
    "bbox = [ 70,  25, 190, 210]\n",
    "image = Chitra(image_path, bboxes=bbox, labels=label)\n",
    "image.image = image.image.resize((224, 224))\n",
    "plt.imshow(image.draw_boxes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils\n",
    "\n",
    "Limit GPU memory or enable dynamic GPU memory growth for Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chitra.utils import limit_gpu, gpu_dynamic_mem_growth\n",
    "\n",
    "# limit the amount of GPU required for your training\n",
    "limit_gpu(gpu_id=0, memory_limit=1024*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_dynamic_mem_growth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contributing\n",
    "\n",
    "Contributions of any kind are welcome. Please check the [**Contributing Guidelines**](https://github.com/aniketmaurya/chitra/blob/master/CONTRIBUTING.md) before contributing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script;notebook2script('index.ipynb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
