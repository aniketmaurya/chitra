{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer\n",
    "> The Trainer class inherits `tf.keras.Model` and contains everything a model needs for training. It exposes `learner.cyclic_fit` method which trains the model using **Cyclic Learning rate** discovered by Leslie Smith."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from typing import Callable, Union\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.models import Model\n",
    "from typeguard import check_argument_types, check_return_type, typechecked\n",
    "\n",
    "from chitra.datagenerator import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tf_keras_vis.gradcam import Gradcam, GradcamPlusPlus\n",
    "from tf_keras_vis.utils import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import inspect\n",
    "import sys\n",
    "\n",
    "MODEL_DICT = {}\n",
    "for name, func in inspect.getmembers(tf.keras.applications):\n",
    "    if inspect.isfunction(func):\n",
    "        MODEL_DICT[name.lower()] = func\n",
    "\n",
    "OPT_DICT = {}\n",
    "for name, func in inspect.getmembers(tf.keras.optimizers):\n",
    "    if inspect.isclass(func):\n",
    "        OPT_DICT[name.lower()] = func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@typechecked\n",
    "def _get_base_cnn(\n",
    "    base_model: Union[str, Model],\n",
    "    pooling: str = \"avg\",\n",
    "    weights: Union[str, None] = \"imagenet\",\n",
    "    include_top: bool = False,\n",
    ") -> Model:\n",
    "    if isinstance(base_model, str):\n",
    "        assert (\n",
    "            base_model in MODEL_DICT.keys()\n",
    "        ), f\"base_model name must be in {tuple(MODEL_DICT.keys())}\"\n",
    "        base_model = MODEL_DICT[base_model]\n",
    "        base_model = base_model(\n",
    "            include_top=include_top, pooling=pooling, weights=weights\n",
    "        )\n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@typechecked\n",
    "def _add_output_layers(\n",
    "    base_model: Model, outputs: int, drop_out: Union[float, None] = None, name=None\n",
    ") -> Model:\n",
    "\n",
    "    x = base_model.output\n",
    "    # x = tf.keras.layers.GlobalMaxPool2D()(x)\n",
    "    if drop_out:\n",
    "        x = tf.keras.layers.Dropout(drop_out)(x)\n",
    "    x = tf.keras.layers.Dense(outputs, name=\"output\")(x)\n",
    "\n",
    "    model = tf.keras.Model(base_model.input, x, name=name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def create_classifier(\n",
    "    base_model_fn: callable,\n",
    "    num_classes: int,\n",
    "    weights=\"imagenet\",\n",
    "    dropout=0,\n",
    "    include_top=False,\n",
    "    name=None,\n",
    "):\n",
    "\n",
    "    outputs = 1 if num_classes == 2 else num_classes\n",
    "\n",
    "    base_model = base_model_fn(\n",
    "        include_top=include_top,\n",
    "        weights=weights,\n",
    "    )\n",
    "    if include_top:\n",
    "        return base_model\n",
    "    drop_out = 0.5\n",
    "    outputs = 1\n",
    "\n",
    "    x = base_model.output\n",
    "    x = tf.keras.layers.GlobalMaxPool2D()(x)\n",
    "    if drop_out:\n",
    "        x = tf.keras.layers.Dropout(drop_out)(x)\n",
    "    x = tf.keras.layers.Dense(outputs, name=\"output\")(x)\n",
    "\n",
    "    model = tf.keras.Model(base_model.input, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@typechecked\n",
    "def create_cnn(\n",
    "    base_model: Union[str, Model],\n",
    "    num_classes: int,\n",
    "    drop_out=0.5,\n",
    "    keras_applications: bool = True,\n",
    "    pooling: str = \"avg\",\n",
    "    weights: Union[str, None] = \"imagenet\",\n",
    "    name=None,\n",
    ") -> Model:\n",
    "\n",
    "    assert pooling in (\"avg\", \"max\")\n",
    "\n",
    "    if keras_applications:\n",
    "        if num_classes == 2:\n",
    "            outputs = 1\n",
    "        else:\n",
    "            outputs = num_classes\n",
    "    else:\n",
    "        print(f\"num_classes is ignored. returning the passed model as it is.\")\n",
    "\n",
    "    if isinstance(base_model, (str, Model)) and keras_applications:\n",
    "        base_model = _get_base_cnn(base_model, pooling=pooling, weights=weights)\n",
    "        assert (\n",
    "            \"pool\" in base_model.layers[-1].name\n",
    "        ), f\"base_model last layer must be a pooling layer\"\n",
    "        model = _add_output_layers(base_model, outputs, drop_out=drop_out, name=name)\n",
    "\n",
    "    elif isinstance(base_model, Model) and keras_applications is False:\n",
    "        model = base_model\n",
    "\n",
    "    elif isinstance(base_model, str) and keras_applications is False:\n",
    "        model = _get_base_cnn(base_model, weights=\"imagenet\", include_top=True)\n",
    "\n",
    "    else:\n",
    "        print(f\"Invalid arguments!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Trainer(Model):\n",
    "    \"\"\"\n",
    "    The Trainer class inherits tf.keras.Model and contains everything a model needs for training.\n",
    "    It exposes trainer.cyclic_fit method which trains the model using Cyclic Learning rate discovered by Leslie Smith.\n",
    "\n",
    "    Arguments:\n",
    "    ds: Dataset object\n",
    "    model: object of type tf.keras.Model\n",
    "    num_classes (int, None): number of classes in the dataset. If None then will auto infer from Dataset\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    _AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "    @typechecked\n",
    "    def __init__(\n",
    "        self, ds: Dataset, model: Model, num_classes: Union[int, None] = None, **kwargs\n",
    "    ):\n",
    "        assert check_argument_types()\n",
    "\n",
    "        super(Trainer, self).__init__()\n",
    "        self.ds = ds\n",
    "        self.total = len(ds)\n",
    "        if num_classes:\n",
    "            self.NUM_CLASSES = num_classes\n",
    "        else:\n",
    "            self.NUM_CLASSES = ds.NUM_CLASSES\n",
    "        self.gradcam = None\n",
    "        self.model = model\n",
    "        self.cyclic_opt_set = False\n",
    "\n",
    "    def build(self):\n",
    "        pass\n",
    "\n",
    "    def summary(self):\n",
    "        return self.model.summary()\n",
    "\n",
    "    # def get_layer(name=None, index=None): return self.model(name, index)\n",
    "\n",
    "    def compile(self, *args, **kwargs):\n",
    "        return self.model.compile(*args, **kwargs)\n",
    "\n",
    "    def call(self, *args, **kwargs):\n",
    "        return self.model.call(*args, **kwargs)\n",
    "\n",
    "    def fit(self, *args, **kwargs):\n",
    "        return self.model.fit(*args, **kwargs)\n",
    "\n",
    "    def warmup(self):\n",
    "        pass\n",
    "\n",
    "    def prewhiten(self, image):\n",
    "        image = tf.cast(image, tf.float32)\n",
    "        image = image / 127.5 - 1.0\n",
    "        return image\n",
    "\n",
    "    def rescale(self, image, label):\n",
    "        image = self.prewhiten(image)\n",
    "        return image, label\n",
    "\n",
    "    def _get_optimizer(self, optimizer, momentum=0.9, **kwargs):\n",
    "        if optimizer.__name__ == \"SGD\":\n",
    "            optimizer = partial(\n",
    "                optimizer, momentum=momentum, nesterov=kwargs.get(\"nesterov\", True)\n",
    "            )\n",
    "        else:\n",
    "            optimizer = partial(\n",
    "                optimizer,\n",
    "                momentum=momentum,\n",
    "            )\n",
    "        return optimizer\n",
    "\n",
    "    def _prepare_dl(self, bs=8, shuffle=True):\n",
    "        ds = self.ds\n",
    "        dl = ds.get_tf_dataset(shuffle=shuffle)\n",
    "        dl = dl.map(self.rescale, Trainer._AUTOTUNE)\n",
    "        return dl.batch(bs).prefetch(Trainer._AUTOTUNE)\n",
    "\n",
    "    def cyclic_fit(\n",
    "        self,\n",
    "        epochs: int,\n",
    "        batch_size: int,\n",
    "        lr_range: Union[tuple, list] = (1e-4, 1e-2),\n",
    "        optimizer=tf.keras.optimizers.SGD,\n",
    "        momentum=0.9,\n",
    "        validation_data=None,\n",
    "        callbacks=None,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Trains model on ds as train data with cyclic learning rate.\n",
    "        Dataset will be automatically converted into `tf.data` format and images will be prewhitened in range of [-1, 1].\n",
    "        Cyclical Learning Rates for Training Neural Networks: https://arxiv.org/abs/1506.01186\n",
    "\n",
    "        Args:\n",
    "            epochs (int): number of epochs for training\n",
    "            batch_size (int): batch size\n",
    "            lr_range (tuple): learning rate will cycle from lr_min to lr_max\n",
    "            optimizer (callable): Keras callable optimizer\n",
    "            momentum(int): momentum for the optimizer\n",
    "        kwargs:\n",
    "            step_size (int): step size for the Cyclic learning rate. By default it is `2 * len(self.ds)//batch_size`\n",
    "            scale_mode (str): cycle or exp\n",
    "            shuffle(bool): Dataset will be shuffle on each epoch if True\n",
    "        \"\"\"\n",
    "        if not self.cyclic_opt_set:\n",
    "            self.max_lr, self.min_lr = lr_range\n",
    "            ds = self.ds\n",
    "            step_size = 2 * len(self.ds) // batch_size\n",
    "            lr_schedule = tfa.optimizers.Triangular2CyclicalLearningRate(\n",
    "                initial_learning_rate=lr_range[0],\n",
    "                maximal_learning_rate=lr_range[1],\n",
    "                step_size=kwargs.get(\"step_size\", step_size),\n",
    "                scale_mode=kwargs.get(\"scale_mode\", \"cycle\"),\n",
    "            )\n",
    "\n",
    "            optimizer = self._get_optimizer(optimizer, momentum=momentum)\n",
    "            optimizer = optimizer(learning_rate=lr_schedule)\n",
    "            self.model.optimizer = optimizer\n",
    "            self.cyclic_opt_set = True\n",
    "        else:\n",
    "            print(\"cyclic learning rate already set!\")\n",
    "\n",
    "        return self.model.fit(\n",
    "            self._prepare_dl(batch_size, kwargs.get(\"shuffle\", True)),\n",
    "            validation_data=validation_data,\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks,\n",
    "        )\n",
    "\n",
    "    @typechecked\n",
    "    def compile2(\n",
    "        self,\n",
    "        batch_size: int,\n",
    "        optimizer: Union[str, tf.keras.optimizers.Optimizer] = \"adam\",\n",
    "        lr_range: Union[tuple, list] = (1e-4, 1e-2),\n",
    "        loss=None,\n",
    "        metrics=None,\n",
    "        loss_weights=None,\n",
    "        weighted_metrics=None,\n",
    "        run_eagerly=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Compile2 compiles the model of Trainer for cyclic learning rate.\n",
    "        Cyclical Learning Rates for Training Neural Networks: https://arxiv.org/abs/1506.01186\n",
    "\n",
    "        Args:\n",
    "            batch_size (int): batch size\n",
    "            lr_range (tuple): learning rate will cycle from lr_min to lr_max\n",
    "            optimizer (str, keras.optimizer.Optimizer): Keras optimizer\n",
    "\n",
    "        kwargs:\n",
    "            step_size (int): step size for the Cyclic learning rate. By default it is `2 * len(self.ds)//batch_size`\n",
    "            scale_mode (str): cycle or exp\n",
    "            momentum(int): momentum for the optimizer when optimizer is of type str\n",
    "        \"\"\"\n",
    "        self.max_lr, self.min_lr = lr_range\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.step_size = step_size = 2 * len(self.ds) // batch_size\n",
    "\n",
    "        lr_schedule = tfa.optimizers.Triangular2CyclicalLearningRate(\n",
    "            initial_learning_rate=lr_range[0],\n",
    "            maximal_learning_rate=lr_range[1],\n",
    "            step_size=kwargs.get(\"step_size\", step_size),\n",
    "            scale_mode=kwargs.get(\"scale_mode\", \"cycle\"),\n",
    "        )\n",
    "\n",
    "        if isinstance(optimizer, str):\n",
    "            optimizer = OPT_DICT[optimizer]\n",
    "            optimizer = optimizer(learning_rate=lr_schedule)\n",
    "            if kwargs.get(\"momentum\"):\n",
    "                optimizer.momentum = kwargs.get(\"momentum\")\n",
    "\n",
    "        else:\n",
    "            optimizer.learning_rate = lr_schedule\n",
    "\n",
    "        self.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "        self.cyclic_opt_set = True\n",
    "        print(f\"Model compiled!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class InterpretModel:\n",
    "    def __init__(self, gradcam_pp: bool, learner: Trainer, clone: bool = False):\n",
    "        \"\"\"Args:\n",
    "        gradcam_pp: if True GradCam class will be used else GradCamPlusplus\n",
    "        clone: whether GradCam will clone learner.model\n",
    "        \"\"\"\n",
    "        if gradcam_pp:\n",
    "            self.gradcam_fn = GradcamPlusPlus\n",
    "        else:\n",
    "            self.gradcam_fn = Gradcam\n",
    "        self.learner = learner\n",
    "\n",
    "        self.gradcam = self.gradcam_fn(learner.model, self.model_modifier, clone=clone)\n",
    "\n",
    "        # if self.learner.include_top is not True:\n",
    "        #     self.gradcam._find_penultimate_output = self.patch\n",
    "\n",
    "    def __call__(self, image: Image.Image, auto_resize: bool = True, image_size=None):\n",
    "        # assert check_argument_types()\n",
    "        gradcam = self.gradcam\n",
    "        get_loss = self.get_loss\n",
    "        if auto_resize and image_size is None:\n",
    "            image_size = self.learner.ds.img_sz_list.get_size()\n",
    "        if image_size:\n",
    "            image = image.resize(image_size)\n",
    "\n",
    "        X = np.asarray(image, np.float32)\n",
    "        X = self.learner.prewhiten(X)\n",
    "        X = np.expand_dims(X, 0)\n",
    "\n",
    "        cam = gradcam(\n",
    "            get_loss,\n",
    "            X,\n",
    "            penultimate_layer=-1,  # model.layers number\n",
    "            seek_penultimate_conv_layer=True,\n",
    "        )\n",
    "        cam = normalize(cam)\n",
    "        heatmap = np.uint8(cm.jet(cam[0])[..., :3] * 255)\n",
    "        plt.imshow(image)\n",
    "        plt.imshow(heatmap, cmap=\"jet\", alpha=0.5)\n",
    "        plt.show()\n",
    "\n",
    "    def __patch(self, *args, **kwargs):\n",
    "        \"\"\"Path _find_penultimate_output method of tf_keras_vis\"\"\"\n",
    "        if self.learner.include_top:\n",
    "            return self.learner.model.layers[-1].output\n",
    "        return self.learner.model.layers[0].get_output_at(-1)\n",
    "\n",
    "    def model_modifier(self, m):\n",
    "        \"\"\"Sets last activation to linear\"\"\"\n",
    "        m.layers[-1].activation = tf.keras.activations.linear\n",
    "        return m\n",
    "\n",
    "    def get_loss(self, preds):\n",
    "        if self.learner.NUM_CLASSES == 2:\n",
    "            ret = preds[0]\n",
    "        else:\n",
    "            index = tf.argmax(tf.math.softmax(preds), axis=1)[0]\n",
    "            # print(index, preds.shape)\n",
    "            ret = preds[0, index]\n",
    "            print(f\"index: {index}\")\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '/data/aniket/tiny-imagenet/data/tiny-imagenet-200/train'\n",
    "path = \"/Users/aniket/Pictures/data/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "from chitra.core import IMAGENET_LABELS\n",
    "\n",
    "\n",
    "def load_files(path):\n",
    "    return glob(f\"{path}/*/images/*\")\n",
    "\n",
    "\n",
    "def get_label(path):\n",
    "    return path.split(\"/\")[-3]\n",
    "\n",
    "\n",
    "ds = Dataset(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_cnn(\n",
    "    tf.keras.applications.MobileNetV2(include_top=True), 1000, keras_applications=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(ds=ds, model=model, num_classes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.compile2(2, \"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret = InterpretModel(False, trainer)\n",
    "\n",
    "# path = '/data/aniket/tiny-imagenet/data/tiny-imagenet-200/train/n01641577/images/n01641577_100.JPEG'\n",
    "path = \"/Users/aniket/Pictures/data/train/cat/2.jpeg\"\n",
    "image = Image.open(path)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret(image, auto_resize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENET_LABELS[285]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from typing import List, Union\n",
    "\n",
    "from tensorflow import keras\n",
    "import pytorch_lightning as pl\n",
    "from chitra.utility.import_utils import INSTALLED_MODULES\n",
    "from chitra.converter.core import tf2_to_onnx, tf2_to_pytorch, onnx_to_pytorch, pytorch_to_onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Learner:\n",
    "    TF = (\"TF\", \"TENSORFLOW\")\n",
    "    PT = (\"PYTORCH\", \"PT\", \"TORCH\")\n",
    "\n",
    "    def __init__(self,\n",
    "                 model: Union[pl.LightningModule, keras.models.Model],\n",
    "                 mode: str = \"TF\"):\n",
    "        self.MODE = mode.upper()\n",
    "        self.model = model\n",
    "        self.epochs_trained = 0\n",
    "\n",
    "        if self.MODE in Learner.PT:\n",
    "            self.trainer = None\n",
    "\n",
    "    def fit(self,\n",
    "            train_data,\n",
    "            epochs,\n",
    "            val_data=None,\n",
    "            test_data=None,\n",
    "            callbacks=None,\n",
    "            **kwargs):\n",
    "        \"\"\"train models\n",
    "        For TF:\n",
    "            Just pass train data and start training\n",
    "        For PyTorch:\n",
    "            You can enter configs to Lightning Trainer\n",
    "        \"\"\"\n",
    "        MODE = self.MODE\n",
    "        initial_epoch = self.epochs_trained\n",
    "        self.epochs_trained += epochs\n",
    "\n",
    "        if MODE in Learner.TF:\n",
    "            return self.model.fit(\n",
    "                train_data,\n",
    "                epochs=epochs,\n",
    "                initial_epoch=initial_epoch,\n",
    "                validation_data=val_data,\n",
    "                callbacks=callbacks,\n",
    "            )\n",
    "        elif MODE in Learner.PT:\n",
    "            lit_confs = kwargs.get('LIT_TRAINER_CONFIG', {})\n",
    "            if not self.trainer:\n",
    "                self.trainer = pl.Trainer(max_epochs=epochs, **lit_confs)\n",
    "            return self.trainer.fit(self.model, train_data, val_data)\n",
    "\n",
    "    def to_onnx(self, tensor=None, export_path=None):\n",
    "        MODE = self.MODE\n",
    "        if MODE in Learner.TF:\n",
    "            return tf2_to_onnx(self.model, output_path=export_path)\n",
    "\n",
    "        if MODE in Learner.PT:\n",
    "            return pytorch_to_onnx(self.model, tensor, export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script(\"06_trainer.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
