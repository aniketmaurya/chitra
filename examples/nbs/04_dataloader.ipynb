{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataloader\n",
    "\n",
    "> Now deprecated, please use datagenerator instead.\n",
    "\n",
    "> **All private functions use primitive datatypes**\n",
    "\n",
    "\n",
    "1. read_image(path: str, channels: int=3)\n",
    "2. clf.load_from_folder\n",
    "3. clf.load_from_csv\n",
    "4. detect.load_from_xml\n",
    "5. detect.load_from_csv\n",
    "6. detect.load_from_json\n",
    "7. detect.load_from_tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Union\n",
    "\n",
    "from chitra.core import remove_dsstore\n",
    "from chitra.image import read_image, resize_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_basename(path: tf.string):\n",
    "    assert isinstance(path, tf.Tensor)\n",
    "    return tf.strings.split(path, os.path.sep)[-1]\n",
    "\n",
    "\n",
    "def show_batch(clf, limit: int, figsize: tuple = (10, 10)):\n",
    "    \"\"\"Visualize image and labels\n",
    "    \n",
    "    https://www.tensorflow.org/tutorials/load_data/images#load_using_keraspreprocessing\n",
    "    \n",
    "    Args:\n",
    "        data: tf.data.Dataset containing image, label\n",
    "        limit: number of images to display\n",
    "        figsize: size of visualization\n",
    "    Returns:\n",
    "        Displays images and labels\n",
    "    \"\"\"\n",
    "    assert isinstance(limit, int)\n",
    "    assert isinstance(figsize, tuple)\n",
    "\n",
    "    data = clf.data\n",
    "    idx_to_class = clf.idx_to_class\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    sub_plot_size = math.ceil(limit / 2)\n",
    "\n",
    "    for i, e in enumerate(data.take(limit)):\n",
    "        image, label = e\n",
    "        image = image.numpy().astype('uint8')\n",
    "        label = idx_to_class[label.numpy()] if idx_to_class else label.numpy()\n",
    "\n",
    "        ax = plt.subplot(sub_plot_size, sub_plot_size, i + 1)\n",
    "\n",
    "        plt.imshow(image)\n",
    "        plt.title(label)\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLF DLoader\n",
    "\n",
    "``DataLoader class for loading dataset for image classification tasks.``\n",
    "\n",
    "## clf.load_from_folder (TODOs)\n",
    "\n",
    "1. `__len__` method impl\n",
    "2. `image augmentation` impl\n",
    "\n",
    "## folder structure\n",
    "\n",
    "><pre>/root\n",
    "    /class1_folder\n",
    "        /img0.jpg img1.jpg img2.jpg ....\n",
    "    /class2_folder\n",
    "        /img0.jpg...</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Clf(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.CLASS_NAMES = None\n",
    "        self.data = None\n",
    "        self.shape = None\n",
    "        self.class_to_idx = {}\n",
    "        self.idx_to_class = {}\n",
    "\n",
    "        self._lookup_class_to_idx = None\n",
    "\n",
    "    def show_batch(self, limit: int, figsize: tuple = (10, 10)):\n",
    "        \"\"\"Visualize image and labels\n",
    "\n",
    "        https://www.tensorflow.org/tutorials/load_data/images#load_using_keraspreprocessing\n",
    "\n",
    "        Args:\n",
    "            data: tf.data.Dataset containing image, label\n",
    "            limit: number of images to display\n",
    "            figsize: size of visualization\n",
    "        Returns:\n",
    "            Displays images and labels\n",
    "        \"\"\"\n",
    "        assert isinstance(limit, int)\n",
    "        assert isinstance(figsize, tuple)\n",
    "\n",
    "        data = self.data\n",
    "        if data is None: raise Exception('TF.data not created yet!')\n",
    "        idx_to_class = self.idx_to_class\n",
    "\n",
    "        plt.figure(figsize=figsize)\n",
    "        sub_plot_size = math.ceil(limit / 2)\n",
    "\n",
    "        for i, e in enumerate(data.take(limit)):\n",
    "            image, label = e\n",
    "            image = image.numpy().astype('uint8')\n",
    "            label = idx_to_class[\n",
    "                label.numpy()] if idx_to_class else label.numpy()\n",
    "\n",
    "            ax = plt.subplot(sub_plot_size, sub_plot_size, i + 1)\n",
    "\n",
    "            plt.imshow(image)\n",
    "            plt.title(label)\n",
    "            plt.axis('off')\n",
    "\n",
    "    def _get_image_list(self, path: str):\n",
    "        \"\"\"`path`: pathlib.Path\n",
    "        Returns: list of images\n",
    "        \"\"\"\n",
    "        assert isinstance(path, str)\n",
    "        list_images = tf.data.Dataset.list_files(f'{path}/*/*')\n",
    "        return list_images\n",
    "\n",
    "    @tf.function\n",
    "    def _process_path(self, path: str):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            `path` :str\n",
    "            `size`: None or tuple\n",
    "        Returns:\n",
    "            image, label\n",
    "        \"\"\"\n",
    "        assert isinstance(\n",
    "            path,\n",
    "            (str,\n",
    "             tf.Tensor)), f'type of path is {type(path)}, expected type str'\n",
    "        img = read_image(path)\n",
    "\n",
    "        # TODO: resizing should be done separately\n",
    "        # py_function will degrade performance\n",
    "        if self.shape:\n",
    "            [\n",
    "                img,\n",
    "            ] = tf.py_function(resize_image, [img, self.shape], [tf.float32])\n",
    "        #         if self.shape:\n",
    "        #             img = tf.image.resize(img, self.shape)\n",
    "\n",
    "        label = tf.strings.split(path, os.path.sep)[-2]\n",
    "        label = self._lookup_class_to_idx.lookup(\n",
    "            label) if self._lookup_class_to_idx else label\n",
    "        return img, label\n",
    "\n",
    "    @tf.function\n",
    "    def _ensure_shape(self, img, labels):\n",
    "        \"\"\"Ensures the output shape of images (InputSpecs)\n",
    "        \"\"\"\n",
    "        img = tf.ensure_shape(img, (*self.shape, 3), name='image')\n",
    "        return img, labels\n",
    "\n",
    "    def create_lookup_table(self):\n",
    "        \"\"\"Creates tf.lookup.StaticHashTable for encoding labels\"\"\"\n",
    "\n",
    "        keys = list(self.class_to_idx.keys())\n",
    "        vals = list(self.class_to_idx.values())\n",
    "\n",
    "        keys_tensor = keys  #tf.constant(keys)\n",
    "        vals_tensor = vals  #tf.constant(vals)\n",
    "\n",
    "        table_init = tf.lookup.KeyValueTensorInitializer(\n",
    "            keys_tensor, vals_tensor)\n",
    "\n",
    "        self._lookup_class_to_idx = tf.lookup.StaticHashTable(table_init, -1)\n",
    "\n",
    "    def _get_classnames(self, list_folders, encode_classes: bool = True):\n",
    "        \"\"\"\"\"\"\n",
    "        self.CLASS_NAMES = tuple(\n",
    "            get_basename(e).numpy().decode() for e in list_folders)\n",
    "        if encode_classes:\n",
    "            self._encode_classes()\n",
    "\n",
    "    def _encode_classes(self):\n",
    "\n",
    "        class_names = sorted(self.CLASS_NAMES)\n",
    "\n",
    "        for i, e in enumerate(class_names):\n",
    "            self.class_to_idx[e] = i\n",
    "            self.idx_to_class[i] = e\n",
    "\n",
    "        self.create_lookup_table()\n",
    "\n",
    "    def from_folder(self,\n",
    "                    path: Union[str, pathlib.Path],\n",
    "                    target_shape: Union[None, tuple] = (224, 224),\n",
    "                    shuffle: Union[bool, int] = True,\n",
    "                    encode_classes: bool = True):\n",
    "        \"\"\"Load dataset from given path.\n",
    "        Args:\n",
    "            path: string, path of folder containing dataset\n",
    "            target_shape: shape of output image\n",
    "            rescale: images will be multiplied by the given value\n",
    "            shuffle: Shuffles the dataset randomly. Expects bool or int.\n",
    "            encode_classes: Will sparse encode classes if True\n",
    "        Returns: image, label -> tf.data.Dataset prefetched with tf.data.AUTOTUNE\n",
    "        \n",
    "        By default the loaded image size is 224x224, pass None to load original size.\n",
    "        You will get error on `batch()` method if all image size are not same.\n",
    "        \"\"\"\n",
    "        assert isinstance(path, (str, pathlib.Path))\n",
    "        assert isinstance(shuffle, (bool, int)), print(f'Arg: shuffle is either bool or int but got {shuffle} : {type(shuffle)}')\n",
    "        \n",
    "        path = pathlib.Path(path)\n",
    "        remove_dsstore(path)\n",
    "\n",
    "        # TODO comments\n",
    "        self.shape = target_shape\n",
    "\n",
    "        list_folders = tf.data.Dataset.list_files(str(path / '*'))\n",
    "        \n",
    "        list_images = self._get_image_list(str(path))\n",
    "        if shuffle: list_images.shuffle(shuffle).cache()\n",
    "        else: list_images.cache()\n",
    "        \n",
    "\n",
    "        self._get_classnames(list_folders, encode_classes)\n",
    "\n",
    "        if encode_classes: print(f'CLASSES ENCODED: {self.class_to_idx}')\n",
    "        else: print(f'CLASSES FOUND: {self.CLASS_NAMES}')    \n",
    "\n",
    "        data = list_images.map(self._process_path, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "        data = data.map(self._ensure_shape, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "        self.data = data\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "path = pathlib.Path('/Users/aniketmaurya/Pictures/cats')\n",
    "\n",
    "clf = Clf()\n",
    "data = clf.from_folder(path, encode_classes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "clf.show_batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect\n",
    "\n",
    "## from_xml\n",
    "### Steps:\n",
    "    . list annotations\n",
    "    . read and parse annotations\n",
    "    . read images\n",
    "    . return images and annotations\n",
    "### folder structure\n",
    "\n",
    "><pre>/root\n",
    "    /image_folder\n",
    "    /annotation_folder</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detect(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.CLASS_NAMES = None\n",
    "\n",
    "    def from_xml(self, path: Union[str, pathlib.Path]):\n",
    "        \"\"\"Load dataset from given path.\n",
    "        Args:\n",
    "            path: string, path of folder containing dataset.\n",
    "        Returns: image, label -> tf.data.Dataset prefetched with tf.data.AUTOTUNE\n",
    "        \"\"\"\n",
    "        assert isinstance(path, (str, pathlib.Path))\n",
    "        path = pathlib.Path(path)\n",
    "        remove_dsstore(path)\n",
    "\n",
    "        list_folders = tf.data.Dataset.list_files(str(path / '*'))\n",
    "        list_images = self._get_image_list(str(path))\n",
    "\n",
    "        self.CLASS_NAMES = tuple(get_basename(e).numpy() for e in list_folders)\n",
    "\n",
    "        data = list_images.map(self._process_path, num_parallel_calls=AUTOTUNE)\n",
    "        data = data.prefetch(AUTOTUNE)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
